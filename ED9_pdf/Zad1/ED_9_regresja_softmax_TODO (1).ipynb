{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Ec9f9O1DIv"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3q9cQ4eWOAr"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdyfkPxi1R0i"
      },
      "source": [
        "# Regresja **softmax**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = [0.2, 0.1, 0.6, 0.1]\n",
        "exps = [np.exp(i) for i in s]\n",
        "sum_of_exps = sum(exps)\n",
        "softmax = [j/sum_of_exps for j in exps]"
      ],
      "metadata": {
        "id": "3X1o2EU34P-T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnJBLhT1CqvE"
      },
      "source": [
        "##3 gangi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YycogTnCoh2"
      },
      "source": [
        "Zbi√≥r danych:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOwn-muw1VnV"
      },
      "source": [
        "x_label0 = np.random.normal(1, 1.5, (1000, 1)) \n",
        "y_label0 = np.random.normal(1, 1.5, (1000, 1)) \n",
        "x_label1 = np.random.normal(5, 1.5, (1000, 1)) \n",
        "y_label1 = np.random.normal(4, 1.5, (1000, 1)) \n",
        "x_label2 = np.random.normal(8, 1.5, (1000, 1)) \n",
        "y_label2 = np.random.normal(0, 1.5, (1000, 1)) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V66I5z4h1gi7"
      },
      "source": [
        "data_label0 = np.concatenate([x_label0, y_label0],axis=1) \n",
        "data_label1 = np.concatenate([x_label1, y_label1],axis=1)  \n",
        "data_label2 = np.concatenate([x_label2, y_label2],axis=1)   \n",
        "points = np.concatenate([data_label0, data_label1, data_label2],axis=0) "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db8Ci1cEElAb"
      },
      "source": [
        "Kodowanie one-hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBuRDDoj14Rv"
      },
      "source": [
        "labels = np.array([[1., 0., 0.]] * len(data_label0) + [[0., 1., 0.]] * len(data_label1) + [[0.,0., 1.]] * len(data_label2))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjMqt1v45iTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f6d85ed-6be3-44e1-a450-b7498f805e03"
      },
      "source": [
        "points.shape,labels.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3000, 2), (3000, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72i6KaPq2Tdm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "4e76c98d-c9c3-460d-d241-cbf2ee9a3318"
      },
      "source": [
        "plt.scatter(x_label0, y_label0, c='r', marker='x', s=20)\n",
        "plt.scatter(x_label1, y_label1, c='b', marker='x', s=20)\n",
        "plt.scatter(x_label2, y_label2, c='g', marker='x', s=20)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "KJG1lBZx80nJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(units = 3, use_bias=True, input_dim=2, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "P9pFcCbT82wn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "#opt = tf.keras.optimizers.SGD(learning_rate=0.1)"
      ],
      "metadata": {
        "id": "Wf1kqdUM84_w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer=opt)"
      ],
      "metadata": {
        "id": "8K36pbpY8691"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDxAeGwe8-cJ",
        "outputId": "2a07138a-52a1-4e31-e41e-456555a9b3bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "#h = model.fit(data_points,labels, verbose=1, epochs=epochs,validation_split=0.2)\n",
        "h = model.fit(points,labels, verbose=1, epochs=epochs, batch_size= 70, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp3RuqO89A41",
        "outputId": "1a0c7b3c-bd86-4d10-f6a3-5f0ce60c7ddf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "35/35 [==============================] - 1s 9ms/step - loss: 1.3370 - val_loss: 2.4286\n",
            "Epoch 2/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.2647 - val_loss: 2.4001\n",
            "Epoch 3/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.1980 - val_loss: 2.3642\n",
            "Epoch 4/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.1366 - val_loss: 2.3146\n",
            "Epoch 5/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.0801 - val_loss: 2.2635\n",
            "Epoch 6/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.0286 - val_loss: 2.1984\n",
            "Epoch 7/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9805 - val_loss: 2.1313\n",
            "Epoch 8/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9358 - val_loss: 2.0582\n",
            "Epoch 9/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8938 - val_loss: 1.9663\n",
            "Epoch 10/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8542 - val_loss: 1.8765\n",
            "Epoch 11/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8164 - val_loss: 1.7853\n",
            "Epoch 12/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7804 - val_loss: 1.6869\n",
            "Epoch 13/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7462 - val_loss: 1.5902\n",
            "Epoch 14/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7138 - val_loss: 1.4954\n",
            "Epoch 15/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6835 - val_loss: 1.3925\n",
            "Epoch 16/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6548 - val_loss: 1.3054\n",
            "Epoch 17/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6285 - val_loss: 1.2178\n",
            "Epoch 18/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 1.1439\n",
            "Epoch 19/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5821 - val_loss: 1.0628\n",
            "Epoch 20/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5621 - val_loss: 0.9897\n",
            "Epoch 21/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5434 - val_loss: 0.9340\n",
            "Epoch 22/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5267 - val_loss: 0.8644\n",
            "Epoch 23/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5113 - val_loss: 0.8167\n",
            "Epoch 24/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4976 - val_loss: 0.7697\n",
            "Epoch 25/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4847 - val_loss: 0.7284\n",
            "Epoch 26/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4731 - val_loss: 0.6918\n",
            "Epoch 27/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.6519\n",
            "Epoch 28/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.6189\n",
            "Epoch 29/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4431 - val_loss: 0.5864\n",
            "Epoch 30/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4344 - val_loss: 0.5654\n",
            "Epoch 31/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4264 - val_loss: 0.5404\n",
            "Epoch 32/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4189 - val_loss: 0.5148\n",
            "Epoch 33/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4960\n",
            "Epoch 34/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4053 - val_loss: 0.4797\n",
            "Epoch 35/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3991 - val_loss: 0.4657\n",
            "Epoch 36/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3932 - val_loss: 0.4524\n",
            "Epoch 37/1000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.3877 - val_loss: 0.4379\n",
            "Epoch 38/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3824 - val_loss: 0.4254\n",
            "Epoch 39/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3774 - val_loss: 0.4129\n",
            "Epoch 40/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3727 - val_loss: 0.4006\n",
            "Epoch 41/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3682 - val_loss: 0.3910\n",
            "Epoch 42/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3639 - val_loss: 0.3849\n",
            "Epoch 43/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3597 - val_loss: 0.3758\n",
            "Epoch 44/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3558 - val_loss: 0.3659\n",
            "Epoch 45/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3520 - val_loss: 0.3589\n",
            "Epoch 46/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3483 - val_loss: 0.3525\n",
            "Epoch 47/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3448 - val_loss: 0.3455\n",
            "Epoch 48/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3414 - val_loss: 0.3405\n",
            "Epoch 49/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3381 - val_loss: 0.3338\n",
            "Epoch 50/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3350 - val_loss: 0.3330\n",
            "Epoch 51/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3318 - val_loss: 0.3222\n",
            "Epoch 52/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3289 - val_loss: 0.3187\n",
            "Epoch 53/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3259 - val_loss: 0.3167\n",
            "Epoch 54/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3231 - val_loss: 0.3124\n",
            "Epoch 55/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3204 - val_loss: 0.3107\n",
            "Epoch 56/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3177 - val_loss: 0.3071\n",
            "Epoch 57/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3151 - val_loss: 0.3028\n",
            "Epoch 58/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3126 - val_loss: 0.3004\n",
            "Epoch 59/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3101 - val_loss: 0.2977\n",
            "Epoch 60/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3077 - val_loss: 0.2945\n",
            "Epoch 61/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3053 - val_loss: 0.2915\n",
            "Epoch 62/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3030 - val_loss: 0.2912\n",
            "Epoch 63/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3007 - val_loss: 0.2884\n",
            "Epoch 64/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2985 - val_loss: 0.2852\n",
            "Epoch 65/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2963 - val_loss: 0.2843\n",
            "Epoch 66/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2942 - val_loss: 0.2831\n",
            "Epoch 67/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2921 - val_loss: 0.2819\n",
            "Epoch 68/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2901 - val_loss: 0.2785\n",
            "Epoch 69/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2881 - val_loss: 0.2786\n",
            "Epoch 70/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2862 - val_loss: 0.2716\n",
            "Epoch 71/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2842 - val_loss: 0.2708\n",
            "Epoch 72/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2824 - val_loss: 0.2697\n",
            "Epoch 73/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2805 - val_loss: 0.2697\n",
            "Epoch 74/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2787 - val_loss: 0.2682\n",
            "Epoch 75/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2769 - val_loss: 0.2658\n",
            "Epoch 76/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2752 - val_loss: 0.2658\n",
            "Epoch 77/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2735 - val_loss: 0.2651\n",
            "Epoch 78/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2718 - val_loss: 0.2641\n",
            "Epoch 79/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2701 - val_loss: 0.2646\n",
            "Epoch 80/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2685 - val_loss: 0.2619\n",
            "Epoch 81/1000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2669 - val_loss: 0.2599\n",
            "Epoch 82/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2653 - val_loss: 0.2597\n",
            "Epoch 83/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2637 - val_loss: 0.2583\n",
            "Epoch 84/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2622 - val_loss: 0.2559\n",
            "Epoch 85/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2607 - val_loss: 0.2551\n",
            "Epoch 86/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2592 - val_loss: 0.2543\n",
            "Epoch 87/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2578 - val_loss: 0.2532\n",
            "Epoch 88/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2564 - val_loss: 0.2536\n",
            "Epoch 89/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2549 - val_loss: 0.2496\n",
            "Epoch 90/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2536 - val_loss: 0.2519\n",
            "Epoch 91/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2522 - val_loss: 0.2489\n",
            "Epoch 92/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2509 - val_loss: 0.2474\n",
            "Epoch 93/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2495 - val_loss: 0.2491\n",
            "Epoch 94/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2482 - val_loss: 0.2492\n",
            "Epoch 95/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2469 - val_loss: 0.2457\n",
            "Epoch 96/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2457 - val_loss: 0.2461\n",
            "Epoch 97/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2444 - val_loss: 0.2450\n",
            "Epoch 98/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2432 - val_loss: 0.2426\n",
            "Epoch 99/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2420 - val_loss: 0.2439\n",
            "Epoch 100/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2408 - val_loss: 0.2425\n",
            "Epoch 101/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2396 - val_loss: 0.2438\n",
            "Epoch 102/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2385 - val_loss: 0.2415\n",
            "Epoch 103/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2373 - val_loss: 0.2424\n",
            "Epoch 104/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2362 - val_loss: 0.2410\n",
            "Epoch 105/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2351 - val_loss: 0.2426\n",
            "Epoch 106/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2340 - val_loss: 0.2399\n",
            "Epoch 107/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2330 - val_loss: 0.2397\n",
            "Epoch 108/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2319 - val_loss: 0.2381\n",
            "Epoch 109/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2308 - val_loss: 0.2366\n",
            "Epoch 110/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2298 - val_loss: 0.2356\n",
            "Epoch 111/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2288 - val_loss: 0.2333\n",
            "Epoch 112/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2278 - val_loss: 0.2350\n",
            "Epoch 113/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2268 - val_loss: 0.2317\n",
            "Epoch 114/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2258 - val_loss: 0.2337\n",
            "Epoch 115/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2248 - val_loss: 0.2319\n",
            "Epoch 116/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2239 - val_loss: 0.2342\n",
            "Epoch 117/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2230 - val_loss: 0.2332\n",
            "Epoch 118/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2220 - val_loss: 0.2327\n",
            "Epoch 119/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2211 - val_loss: 0.2322\n",
            "Epoch 120/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2202 - val_loss: 0.2314\n",
            "Epoch 121/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2193 - val_loss: 0.2333\n",
            "Epoch 122/1000\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2185 - val_loss: 0.2307\n",
            "Epoch 123/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2176 - val_loss: 0.2301\n",
            "Epoch 124/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2168 - val_loss: 0.2308\n",
            "Epoch 125/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2159 - val_loss: 0.2271\n",
            "Epoch 126/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2151 - val_loss: 0.2277\n",
            "Epoch 127/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2143 - val_loss: 0.2302\n",
            "Epoch 128/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2135 - val_loss: 0.2244\n",
            "Epoch 129/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2127 - val_loss: 0.2250\n",
            "Epoch 130/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2119 - val_loss: 0.2258\n",
            "Epoch 131/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2112 - val_loss: 0.2245\n",
            "Epoch 132/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2104 - val_loss: 0.2252\n",
            "Epoch 133/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2096 - val_loss: 0.2257\n",
            "Epoch 134/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2089 - val_loss: 0.2263\n",
            "Epoch 135/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2082 - val_loss: 0.2247\n",
            "Epoch 136/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2074 - val_loss: 0.2262\n",
            "Epoch 137/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2068 - val_loss: 0.2267\n",
            "Epoch 138/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2060 - val_loss: 0.2263\n",
            "Epoch 139/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2054 - val_loss: 0.2269\n",
            "Epoch 140/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.2219\n",
            "Epoch 141/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2040 - val_loss: 0.2219\n",
            "Epoch 142/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2033 - val_loss: 0.2247\n",
            "Epoch 143/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2027 - val_loss: 0.2246\n",
            "Epoch 144/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2020 - val_loss: 0.2234\n",
            "Epoch 145/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2013 - val_loss: 0.2224\n",
            "Epoch 146/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2008 - val_loss: 0.2217\n",
            "Epoch 147/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2001 - val_loss: 0.2213\n",
            "Epoch 148/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.2215\n",
            "Epoch 149/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1989 - val_loss: 0.2222\n",
            "Epoch 150/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.2208\n",
            "Epoch 151/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1977 - val_loss: 0.2236\n",
            "Epoch 152/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1971 - val_loss: 0.2188\n",
            "Epoch 153/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1965 - val_loss: 0.2189\n",
            "Epoch 154/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1959 - val_loss: 0.2186\n",
            "Epoch 155/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1954 - val_loss: 0.2206\n",
            "Epoch 156/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1948 - val_loss: 0.2182\n",
            "Epoch 157/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1943 - val_loss: 0.2203\n",
            "Epoch 158/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1938 - val_loss: 0.2174\n",
            "Epoch 159/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1933 - val_loss: 0.2171\n",
            "Epoch 160/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1927 - val_loss: 0.2157\n",
            "Epoch 161/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1922 - val_loss: 0.2173\n",
            "Epoch 162/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1917 - val_loss: 0.2139\n",
            "Epoch 163/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1912 - val_loss: 0.2192\n",
            "Epoch 164/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1907 - val_loss: 0.2168\n",
            "Epoch 165/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1902 - val_loss: 0.2164\n",
            "Epoch 166/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1897 - val_loss: 0.2160\n",
            "Epoch 167/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1893 - val_loss: 0.2124\n",
            "Epoch 168/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1888 - val_loss: 0.2191\n",
            "Epoch 169/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1883 - val_loss: 0.2186\n",
            "Epoch 170/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1878 - val_loss: 0.2166\n",
            "Epoch 171/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1874 - val_loss: 0.2137\n",
            "Epoch 172/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1869 - val_loss: 0.2160\n",
            "Epoch 173/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.2136\n",
            "Epoch 174/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.2175\n",
            "Epoch 175/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.2131\n",
            "Epoch 176/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.2135\n",
            "Epoch 177/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1848 - val_loss: 0.2148\n",
            "Epoch 178/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1844 - val_loss: 0.2132\n",
            "Epoch 179/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1840 - val_loss: 0.2128\n",
            "Epoch 180/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1836 - val_loss: 0.2122\n",
            "Epoch 181/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.2134\n",
            "Epoch 182/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1828 - val_loss: 0.2110\n",
            "Epoch 183/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1824 - val_loss: 0.2125\n",
            "Epoch 184/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1820 - val_loss: 0.2137\n",
            "Epoch 185/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1817 - val_loss: 0.2107\n",
            "Epoch 186/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.2118\n",
            "Epoch 187/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.2076\n",
            "Epoch 188/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.2111\n",
            "Epoch 189/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1802 - val_loss: 0.2112\n",
            "Epoch 190/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1798 - val_loss: 0.2085\n",
            "Epoch 191/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 0.2082\n",
            "Epoch 192/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1792 - val_loss: 0.2082\n",
            "Epoch 193/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1789 - val_loss: 0.2062\n",
            "Epoch 194/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1785 - val_loss: 0.2101\n",
            "Epoch 195/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1782 - val_loss: 0.2137\n",
            "Epoch 196/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1779 - val_loss: 0.2125\n",
            "Epoch 197/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1776 - val_loss: 0.2100\n",
            "Epoch 198/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1773 - val_loss: 0.2120\n",
            "Epoch 199/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1769 - val_loss: 0.2119\n",
            "Epoch 200/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1767 - val_loss: 0.2076\n",
            "Epoch 201/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1763 - val_loss: 0.2091\n",
            "Epoch 202/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1761 - val_loss: 0.2090\n",
            "Epoch 203/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1758 - val_loss: 0.2079\n",
            "Epoch 204/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1754 - val_loss: 0.2074\n",
            "Epoch 205/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1752 - val_loss: 0.2096\n",
            "Epoch 206/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1749 - val_loss: 0.2044\n",
            "Epoch 207/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1746 - val_loss: 0.2069\n",
            "Epoch 208/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1744 - val_loss: 0.2088\n",
            "Epoch 209/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1741 - val_loss: 0.2087\n",
            "Epoch 210/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1738 - val_loss: 0.2063\n",
            "Epoch 211/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1736 - val_loss: 0.2097\n",
            "Epoch 212/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1733 - val_loss: 0.2085\n",
            "Epoch 213/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1731 - val_loss: 0.2075\n",
            "Epoch 214/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1728 - val_loss: 0.2076\n",
            "Epoch 215/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1726 - val_loss: 0.2076\n",
            "Epoch 216/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1723 - val_loss: 0.2068\n",
            "Epoch 217/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1721 - val_loss: 0.2057\n",
            "Epoch 218/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1718 - val_loss: 0.2044\n",
            "Epoch 219/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1716 - val_loss: 0.2097\n",
            "Epoch 220/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1714 - val_loss: 0.2035\n",
            "Epoch 221/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1711 - val_loss: 0.2049\n",
            "Epoch 222/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1709 - val_loss: 0.2073\n",
            "Epoch 223/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1707 - val_loss: 0.2050\n",
            "Epoch 224/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1704 - val_loss: 0.2084\n",
            "Epoch 225/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1702 - val_loss: 0.2088\n",
            "Epoch 226/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1700 - val_loss: 0.2085\n",
            "Epoch 227/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1699 - val_loss: 0.2051\n",
            "Epoch 228/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1696 - val_loss: 0.2066\n",
            "Epoch 229/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1694 - val_loss: 0.2074\n",
            "Epoch 230/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1692 - val_loss: 0.2072\n",
            "Epoch 231/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1690 - val_loss: 0.2031\n",
            "Epoch 232/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1688 - val_loss: 0.2061\n",
            "Epoch 233/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1687 - val_loss: 0.2051\n",
            "Epoch 234/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1685 - val_loss: 0.2059\n",
            "Epoch 235/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1683 - val_loss: 0.2049\n",
            "Epoch 236/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1681 - val_loss: 0.2059\n",
            "Epoch 237/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1679 - val_loss: 0.2033\n",
            "Epoch 238/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1677 - val_loss: 0.2049\n",
            "Epoch 239/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1675 - val_loss: 0.2063\n",
            "Epoch 240/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1674 - val_loss: 0.2061\n",
            "Epoch 241/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1673 - val_loss: 0.2034\n",
            "Epoch 242/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1670 - val_loss: 0.2060\n",
            "Epoch 243/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1668 - val_loss: 0.2064\n",
            "Epoch 244/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1667 - val_loss: 0.2066\n",
            "Epoch 245/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1665 - val_loss: 0.2052\n",
            "Epoch 246/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1664 - val_loss: 0.2034\n",
            "Epoch 247/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1663 - val_loss: 0.2060\n",
            "Epoch 248/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1660 - val_loss: 0.2057\n",
            "Epoch 249/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1659 - val_loss: 0.2062\n",
            "Epoch 250/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1658 - val_loss: 0.2055\n",
            "Epoch 251/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1656 - val_loss: 0.2043\n",
            "Epoch 252/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1655 - val_loss: 0.2040\n",
            "Epoch 253/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1653 - val_loss: 0.2049\n",
            "Epoch 254/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1652 - val_loss: 0.2062\n",
            "Epoch 255/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1650 - val_loss: 0.2072\n",
            "Epoch 256/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1649 - val_loss: 0.2050\n",
            "Epoch 257/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.2044\n",
            "Epoch 258/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1646 - val_loss: 0.2058\n",
            "Epoch 259/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1645 - val_loss: 0.2054\n",
            "Epoch 260/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1643 - val_loss: 0.2065\n",
            "Epoch 261/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1642 - val_loss: 0.2037\n",
            "Epoch 262/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1640 - val_loss: 0.2051\n",
            "Epoch 263/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1640 - val_loss: 0.2038\n",
            "Epoch 264/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1638 - val_loss: 0.2029\n",
            "Epoch 265/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1638 - val_loss: 0.2042\n",
            "Epoch 266/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1637 - val_loss: 0.1995\n",
            "Epoch 267/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1634 - val_loss: 0.2072\n",
            "Epoch 268/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1633 - val_loss: 0.2065\n",
            "Epoch 269/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1632 - val_loss: 0.2028\n",
            "Epoch 270/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1631 - val_loss: 0.2026\n",
            "Epoch 271/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1630 - val_loss: 0.2013\n",
            "Epoch 272/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1628 - val_loss: 0.2035\n",
            "Epoch 273/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1627 - val_loss: 0.2039\n",
            "Epoch 274/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1627 - val_loss: 0.2044\n",
            "Epoch 275/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1626 - val_loss: 0.2054\n",
            "Epoch 276/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1624 - val_loss: 0.2028\n",
            "Epoch 277/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1623 - val_loss: 0.2043\n",
            "Epoch 278/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1623 - val_loss: 0.2061\n",
            "Epoch 279/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1621 - val_loss: 0.2037\n",
            "Epoch 280/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.2021\n",
            "Epoch 281/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1619 - val_loss: 0.2025\n",
            "Epoch 282/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1618 - val_loss: 0.2036\n",
            "Epoch 283/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1618 - val_loss: 0.2008\n",
            "Epoch 284/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1616 - val_loss: 0.2043\n",
            "Epoch 285/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1615 - val_loss: 0.2060\n",
            "Epoch 286/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1615 - val_loss: 0.2042\n",
            "Epoch 287/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1613 - val_loss: 0.2008\n",
            "Epoch 288/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1612 - val_loss: 0.2011\n",
            "Epoch 289/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1612 - val_loss: 0.2037\n",
            "Epoch 290/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1611 - val_loss: 0.2033\n",
            "Epoch 291/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1609 - val_loss: 0.2024\n",
            "Epoch 292/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1609 - val_loss: 0.2007\n",
            "Epoch 293/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.2025\n",
            "Epoch 294/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1607 - val_loss: 0.2022\n",
            "Epoch 295/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1606 - val_loss: 0.2020\n",
            "Epoch 296/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1605 - val_loss: 0.2031\n",
            "Epoch 297/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1604 - val_loss: 0.2032\n",
            "Epoch 298/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.2045\n",
            "Epoch 299/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1603 - val_loss: 0.2028\n",
            "Epoch 300/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1602 - val_loss: 0.2040\n",
            "Epoch 301/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1601 - val_loss: 0.2033\n",
            "Epoch 302/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1601 - val_loss: 0.2013\n",
            "Epoch 303/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1600 - val_loss: 0.2039\n",
            "Epoch 304/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1600 - val_loss: 0.2014\n",
            "Epoch 305/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1599 - val_loss: 0.2029\n",
            "Epoch 306/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1598 - val_loss: 0.2021\n",
            "Epoch 307/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1598 - val_loss: 0.2026\n",
            "Epoch 308/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1596 - val_loss: 0.2033\n",
            "Epoch 309/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1596 - val_loss: 0.2037\n",
            "Epoch 310/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1595 - val_loss: 0.2047\n",
            "Epoch 311/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1595 - val_loss: 0.2053\n",
            "Epoch 312/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1594 - val_loss: 0.2053\n",
            "Epoch 313/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1594 - val_loss: 0.2034\n",
            "Epoch 314/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1592 - val_loss: 0.2024\n",
            "Epoch 315/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1592 - val_loss: 0.2017\n",
            "Epoch 316/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1591 - val_loss: 0.2028\n",
            "Epoch 317/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1591 - val_loss: 0.1995\n",
            "Epoch 318/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1590 - val_loss: 0.2014\n",
            "Epoch 319/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1589 - val_loss: 0.2017\n",
            "Epoch 320/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1588 - val_loss: 0.1992\n",
            "Epoch 321/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1588 - val_loss: 0.2005\n",
            "Epoch 322/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1588 - val_loss: 0.2015\n",
            "Epoch 323/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1587 - val_loss: 0.2022\n",
            "Epoch 324/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1586 - val_loss: 0.2009\n",
            "Epoch 325/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1586 - val_loss: 0.2025\n",
            "Epoch 326/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1585 - val_loss: 0.2003\n",
            "Epoch 327/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1585 - val_loss: 0.1996\n",
            "Epoch 328/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1585 - val_loss: 0.2014\n",
            "Epoch 329/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1584 - val_loss: 0.2006\n",
            "Epoch 330/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1583 - val_loss: 0.1997\n",
            "Epoch 331/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1583 - val_loss: 0.2003\n",
            "Epoch 332/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1582 - val_loss: 0.1989\n",
            "Epoch 333/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1582 - val_loss: 0.1990\n",
            "Epoch 334/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1581 - val_loss: 0.1992\n",
            "Epoch 335/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1580 - val_loss: 0.2030\n",
            "Epoch 336/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1580 - val_loss: 0.1997\n",
            "Epoch 337/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 0.2019\n",
            "Epoch 338/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 0.2009\n",
            "Epoch 339/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1578 - val_loss: 0.2002\n",
            "Epoch 340/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1578 - val_loss: 0.1988\n",
            "Epoch 341/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1578 - val_loss: 0.2035\n",
            "Epoch 342/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1577 - val_loss: 0.2018\n",
            "Epoch 343/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1576 - val_loss: 0.1996\n",
            "Epoch 344/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1576 - val_loss: 0.1990\n",
            "Epoch 345/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1576 - val_loss: 0.2002\n",
            "Epoch 346/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 0.2011\n",
            "Epoch 347/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 0.2023\n",
            "Epoch 348/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 0.2002\n",
            "Epoch 349/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1574 - val_loss: 0.2017\n",
            "Epoch 350/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1573 - val_loss: 0.1984\n",
            "Epoch 351/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1574 - val_loss: 0.1998\n",
            "Epoch 352/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1573 - val_loss: 0.2005\n",
            "Epoch 353/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1572 - val_loss: 0.1982\n",
            "Epoch 354/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1572 - val_loss: 0.1992\n",
            "Epoch 355/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1571 - val_loss: 0.1996\n",
            "Epoch 356/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1571 - val_loss: 0.2002\n",
            "Epoch 357/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1571 - val_loss: 0.2001\n",
            "Epoch 358/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1570 - val_loss: 0.2009\n",
            "Epoch 359/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1570 - val_loss: 0.1996\n",
            "Epoch 360/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1570 - val_loss: 0.2005\n",
            "Epoch 361/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1569 - val_loss: 0.1976\n",
            "Epoch 362/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1569 - val_loss: 0.1993\n",
            "Epoch 363/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1568 - val_loss: 0.1968\n",
            "Epoch 364/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1568 - val_loss: 0.2017\n",
            "Epoch 365/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1568 - val_loss: 0.2013\n",
            "Epoch 366/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1568 - val_loss: 0.2005\n",
            "Epoch 367/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1568 - val_loss: 0.2004\n",
            "Epoch 368/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.2000\n",
            "Epoch 369/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 0.2001\n",
            "Epoch 370/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 0.1993\n",
            "Epoch 371/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 0.2034\n",
            "Epoch 372/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 0.1996\n",
            "Epoch 373/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 0.1999\n",
            "Epoch 374/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1564 - val_loss: 0.1999\n",
            "Epoch 375/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1565 - val_loss: 0.1979\n",
            "Epoch 376/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1564 - val_loss: 0.1992\n",
            "Epoch 377/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1564 - val_loss: 0.1982\n",
            "Epoch 378/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1564 - val_loss: 0.1993\n",
            "Epoch 379/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1563 - val_loss: 0.2001\n",
            "Epoch 380/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1563 - val_loss: 0.1999\n",
            "Epoch 381/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1562 - val_loss: 0.1984\n",
            "Epoch 382/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1562 - val_loss: 0.1984\n",
            "Epoch 383/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1563 - val_loss: 0.2006\n",
            "Epoch 384/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1562 - val_loss: 0.2010\n",
            "Epoch 385/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 0.1991\n",
            "Epoch 386/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 0.1999\n",
            "Epoch 387/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 0.1960\n",
            "Epoch 388/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 0.1979\n",
            "Epoch 389/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1560 - val_loss: 0.1989\n",
            "Epoch 390/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1560 - val_loss: 0.1950\n",
            "Epoch 391/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.1987\n",
            "Epoch 392/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.2002\n",
            "Epoch 393/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.1994\n",
            "Epoch 394/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.2008\n",
            "Epoch 395/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.2013\n",
            "Epoch 396/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1558 - val_loss: 0.2012\n",
            "Epoch 397/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1558 - val_loss: 0.1991\n",
            "Epoch 398/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1558 - val_loss: 0.1993\n",
            "Epoch 399/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1984\n",
            "Epoch 400/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1558 - val_loss: 0.1998\n",
            "Epoch 401/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1952\n",
            "Epoch 402/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1989\n",
            "Epoch 403/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1964\n",
            "Epoch 404/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1991\n",
            "Epoch 405/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1982\n",
            "Epoch 406/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1556 - val_loss: 0.2007\n",
            "Epoch 407/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1556 - val_loss: 0.1988\n",
            "Epoch 408/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1556 - val_loss: 0.1992\n",
            "Epoch 409/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1555 - val_loss: 0.2001\n",
            "Epoch 410/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1555 - val_loss: 0.1996\n",
            "Epoch 411/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1555 - val_loss: 0.1978\n",
            "Epoch 412/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1555 - val_loss: 0.1990\n",
            "Epoch 413/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1555 - val_loss: 0.1984\n",
            "Epoch 414/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.1975\n",
            "Epoch 415/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.1988\n",
            "Epoch 416/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.1978\n",
            "Epoch 417/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.1954\n",
            "Epoch 418/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.2020\n",
            "Epoch 419/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1553 - val_loss: 0.1994\n",
            "Epoch 420/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1553 - val_loss: 0.1958\n",
            "Epoch 421/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1553 - val_loss: 0.2002\n",
            "Epoch 422/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 0.1989\n",
            "Epoch 423/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1553 - val_loss: 0.1996\n",
            "Epoch 424/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 0.1989\n",
            "Epoch 425/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 0.1973\n",
            "Epoch 426/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 0.2007\n",
            "Epoch 427/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 0.2012\n",
            "Epoch 428/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1551 - val_loss: 0.2002\n",
            "Epoch 429/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 0.1996\n",
            "Epoch 430/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1551 - val_loss: 0.1989\n",
            "Epoch 431/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 0.1961\n",
            "Epoch 432/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1551 - val_loss: 0.1987\n",
            "Epoch 433/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1985\n",
            "Epoch 434/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1966\n",
            "Epoch 435/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1975\n",
            "Epoch 436/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1990\n",
            "Epoch 437/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.2003\n",
            "Epoch 438/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1549 - val_loss: 0.1959\n",
            "Epoch 439/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1966\n",
            "Epoch 440/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1975\n",
            "Epoch 441/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1995\n",
            "Epoch 442/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1993\n",
            "Epoch 443/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1968\n",
            "Epoch 444/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.2005\n",
            "Epoch 445/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1979\n",
            "Epoch 446/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1976\n",
            "Epoch 447/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1990\n",
            "Epoch 448/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.2002\n",
            "Epoch 449/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.2006\n",
            "Epoch 450/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1957\n",
            "Epoch 451/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1993\n",
            "Epoch 452/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1989\n",
            "Epoch 453/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 0.1965\n",
            "Epoch 454/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 0.1957\n",
            "Epoch 455/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 0.1978\n",
            "Epoch 456/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 0.1974\n",
            "Epoch 457/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.2014\n",
            "Epoch 458/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 0.1983\n",
            "Epoch 459/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 0.1999\n",
            "Epoch 460/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.2003\n",
            "Epoch 461/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1982\n",
            "Epoch 462/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1988\n",
            "Epoch 463/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1958\n",
            "Epoch 464/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1998\n",
            "Epoch 465/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1963\n",
            "Epoch 466/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1968\n",
            "Epoch 467/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1997\n",
            "Epoch 468/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1980\n",
            "Epoch 469/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1981\n",
            "Epoch 470/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1999\n",
            "Epoch 471/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1998\n",
            "Epoch 472/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1973\n",
            "Epoch 473/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1983\n",
            "Epoch 474/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1964\n",
            "Epoch 475/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1994\n",
            "Epoch 476/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1962\n",
            "Epoch 477/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1985\n",
            "Epoch 478/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1950\n",
            "Epoch 479/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1972\n",
            "Epoch 480/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1954\n",
            "Epoch 481/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1969\n",
            "Epoch 482/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1965\n",
            "Epoch 483/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.2007\n",
            "Epoch 484/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.2018\n",
            "Epoch 485/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.2003\n",
            "Epoch 486/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.2001\n",
            "Epoch 487/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1999\n",
            "Epoch 488/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1961\n",
            "Epoch 489/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1975\n",
            "Epoch 490/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1989\n",
            "Epoch 491/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1978\n",
            "Epoch 492/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1994\n",
            "Epoch 493/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1998\n",
            "Epoch 494/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.2001\n",
            "Epoch 495/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1983\n",
            "Epoch 496/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1975\n",
            "Epoch 497/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1977\n",
            "Epoch 498/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1963\n",
            "Epoch 499/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1967\n",
            "Epoch 500/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1953\n",
            "Epoch 501/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1994\n",
            "Epoch 502/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1975\n",
            "Epoch 503/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1966\n",
            "Epoch 504/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1977\n",
            "Epoch 505/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1975\n",
            "Epoch 506/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1967\n",
            "Epoch 507/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1983\n",
            "Epoch 508/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1939\n",
            "Epoch 509/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1995\n",
            "Epoch 510/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1990\n",
            "Epoch 511/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1990\n",
            "Epoch 512/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1979\n",
            "Epoch 513/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1939\n",
            "Epoch 514/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1944\n",
            "Epoch 515/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1963\n",
            "Epoch 516/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1985\n",
            "Epoch 517/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1965\n",
            "Epoch 518/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1958\n",
            "Epoch 519/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1956\n",
            "Epoch 520/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1952\n",
            "Epoch 521/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1980\n",
            "Epoch 522/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1972\n",
            "Epoch 523/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1958\n",
            "Epoch 524/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1967\n",
            "Epoch 525/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1983\n",
            "Epoch 526/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1980\n",
            "Epoch 527/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1983\n",
            "Epoch 528/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1962\n",
            "Epoch 529/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1983\n",
            "Epoch 530/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1965\n",
            "Epoch 531/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1983\n",
            "Epoch 532/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1955\n",
            "Epoch 533/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1990\n",
            "Epoch 534/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1975\n",
            "Epoch 535/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1930\n",
            "Epoch 536/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1950\n",
            "Epoch 537/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1969\n",
            "Epoch 538/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1972\n",
            "Epoch 539/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1953\n",
            "Epoch 540/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1981\n",
            "Epoch 541/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1971\n",
            "Epoch 542/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1987\n",
            "Epoch 543/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1962\n",
            "Epoch 544/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1964\n",
            "Epoch 545/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1982\n",
            "Epoch 546/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1983\n",
            "Epoch 547/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1981\n",
            "Epoch 548/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.2004\n",
            "Epoch 549/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1959\n",
            "Epoch 550/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1996\n",
            "Epoch 551/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1984\n",
            "Epoch 552/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1984\n",
            "Epoch 553/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1993\n",
            "Epoch 554/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1975\n",
            "Epoch 555/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1971\n",
            "Epoch 556/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1995\n",
            "Epoch 557/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1974\n",
            "Epoch 558/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1959\n",
            "Epoch 559/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1972\n",
            "Epoch 560/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1974\n",
            "Epoch 561/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1985\n",
            "Epoch 562/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1968\n",
            "Epoch 563/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1949\n",
            "Epoch 564/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1961\n",
            "Epoch 565/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1952\n",
            "Epoch 566/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1955\n",
            "Epoch 567/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1958\n",
            "Epoch 568/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1967\n",
            "Epoch 569/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1942\n",
            "Epoch 570/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1972\n",
            "Epoch 571/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1987\n",
            "Epoch 572/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1978\n",
            "Epoch 573/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1974\n",
            "Epoch 574/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1958\n",
            "Epoch 575/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1959\n",
            "Epoch 576/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1953\n",
            "Epoch 577/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1962\n",
            "Epoch 578/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1965\n",
            "Epoch 579/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1987\n",
            "Epoch 580/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1971\n",
            "Epoch 581/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1977\n",
            "Epoch 582/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1992\n",
            "Epoch 583/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1968\n",
            "Epoch 584/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1974\n",
            "Epoch 585/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1970\n",
            "Epoch 586/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1981\n",
            "Epoch 587/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1983\n",
            "Epoch 588/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1535 - val_loss: 0.1984\n",
            "Epoch 589/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1978\n",
            "Epoch 590/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1971\n",
            "Epoch 591/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1959\n",
            "Epoch 592/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1964\n",
            "Epoch 593/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1958\n",
            "Epoch 594/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1953\n",
            "Epoch 595/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1984\n",
            "Epoch 596/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1989\n",
            "Epoch 597/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1957\n",
            "Epoch 598/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1973\n",
            "Epoch 599/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1977\n",
            "Epoch 600/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1964\n",
            "Epoch 601/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1993\n",
            "Epoch 602/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1963\n",
            "Epoch 603/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1969\n",
            "Epoch 604/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1978\n",
            "Epoch 605/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1961\n",
            "Epoch 606/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1987\n",
            "Epoch 607/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1993\n",
            "Epoch 608/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1995\n",
            "Epoch 609/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1967\n",
            "Epoch 610/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.2006\n",
            "Epoch 611/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1965\n",
            "Epoch 612/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1987\n",
            "Epoch 613/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1971\n",
            "Epoch 614/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1972\n",
            "Epoch 615/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.2001\n",
            "Epoch 616/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.2008\n",
            "Epoch 617/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1970\n",
            "Epoch 618/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1979\n",
            "Epoch 619/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1996\n",
            "Epoch 620/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1969\n",
            "Epoch 621/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1954\n",
            "Epoch 622/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1956\n",
            "Epoch 623/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1982\n",
            "Epoch 624/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1958\n",
            "Epoch 625/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1935\n",
            "Epoch 626/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1959\n",
            "Epoch 627/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1978\n",
            "Epoch 628/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1963\n",
            "Epoch 629/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1973\n",
            "Epoch 630/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1967\n",
            "Epoch 631/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1964\n",
            "Epoch 632/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1948\n",
            "Epoch 633/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1948\n",
            "Epoch 634/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1961\n",
            "Epoch 635/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1970\n",
            "Epoch 636/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1958\n",
            "Epoch 637/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1952\n",
            "Epoch 638/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1951\n",
            "Epoch 639/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1533 - val_loss: 0.1955\n",
            "Epoch 640/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1954\n",
            "Epoch 641/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1960\n",
            "Epoch 642/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1964\n",
            "Epoch 643/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1972\n",
            "Epoch 644/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1965\n",
            "Epoch 645/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1964\n",
            "Epoch 646/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.2000\n",
            "Epoch 647/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1989\n",
            "Epoch 648/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1999\n",
            "Epoch 649/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1964\n",
            "Epoch 650/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1959\n",
            "Epoch 651/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1938\n",
            "Epoch 652/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1970\n",
            "Epoch 653/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1965\n",
            "Epoch 654/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1973\n",
            "Epoch 655/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1974\n",
            "Epoch 656/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1992\n",
            "Epoch 657/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1533 - val_loss: 0.1969\n",
            "Epoch 658/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1964\n",
            "Epoch 659/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1959\n",
            "Epoch 660/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1959\n",
            "Epoch 661/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1962\n",
            "Epoch 662/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1962\n",
            "Epoch 663/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1950\n",
            "Epoch 664/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1954\n",
            "Epoch 665/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.2017\n",
            "Epoch 666/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1533 - val_loss: 0.1985\n",
            "Epoch 667/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1948\n",
            "Epoch 668/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1980\n",
            "Epoch 669/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1983\n",
            "Epoch 670/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1972\n",
            "Epoch 671/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1990\n",
            "Epoch 672/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.2006\n",
            "Epoch 673/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1989\n",
            "Epoch 674/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1533 - val_loss: 0.1963\n",
            "Epoch 675/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1981\n",
            "Epoch 676/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1983\n",
            "Epoch 677/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1989\n",
            "Epoch 678/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1995\n",
            "Epoch 679/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1982\n",
            "Epoch 680/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1995\n",
            "Epoch 681/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.2000\n",
            "Epoch 682/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1972\n",
            "Epoch 683/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1980\n",
            "Epoch 684/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1975\n",
            "Epoch 685/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1961\n",
            "Epoch 686/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1971\n",
            "Epoch 687/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1950\n",
            "Epoch 688/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1966\n",
            "Epoch 689/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1967\n",
            "Epoch 690/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1945\n",
            "Epoch 691/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.2009\n",
            "Epoch 692/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1954\n",
            "Epoch 693/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1973\n",
            "Epoch 694/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1946\n",
            "Epoch 695/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1960\n",
            "Epoch 696/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1968\n",
            "Epoch 697/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1969\n",
            "Epoch 698/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1988\n",
            "Epoch 699/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1952\n",
            "Epoch 700/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1959\n",
            "Epoch 701/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1963\n",
            "Epoch 702/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1978\n",
            "Epoch 703/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1966\n",
            "Epoch 704/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1990\n",
            "Epoch 705/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1975\n",
            "Epoch 706/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1970\n",
            "Epoch 707/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1962\n",
            "Epoch 708/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1965\n",
            "Epoch 709/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1940\n",
            "Epoch 710/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1969\n",
            "Epoch 711/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1961\n",
            "Epoch 712/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1975\n",
            "Epoch 713/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1974\n",
            "Epoch 714/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1960\n",
            "Epoch 715/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1980\n",
            "Epoch 716/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1974\n",
            "Epoch 717/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1972\n",
            "Epoch 718/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1532 - val_loss: 0.1990\n",
            "Epoch 719/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1977\n",
            "Epoch 720/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1988\n",
            "Epoch 721/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1980\n",
            "Epoch 722/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1968\n",
            "Epoch 723/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1990\n",
            "Epoch 724/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1969\n",
            "Epoch 725/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1988\n",
            "Epoch 726/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1965\n",
            "Epoch 727/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1960\n",
            "Epoch 728/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1997\n",
            "Epoch 729/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1966\n",
            "Epoch 730/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1978\n",
            "Epoch 731/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1989\n",
            "Epoch 732/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1980\n",
            "Epoch 733/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1982\n",
            "Epoch 734/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1960\n",
            "Epoch 735/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1961\n",
            "Epoch 736/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1974\n",
            "Epoch 737/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1949\n",
            "Epoch 738/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1967\n",
            "Epoch 739/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1986\n",
            "Epoch 740/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1981\n",
            "Epoch 741/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1976\n",
            "Epoch 742/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1953\n",
            "Epoch 743/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1984\n",
            "Epoch 744/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1975\n",
            "Epoch 745/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1531 - val_loss: 0.1987\n",
            "Epoch 746/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1988\n",
            "Epoch 747/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1975\n",
            "Epoch 748/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1982\n",
            "Epoch 749/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1994\n",
            "Epoch 750/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1945\n",
            "Epoch 751/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1950\n",
            "Epoch 752/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1980\n",
            "Epoch 753/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1531 - val_loss: 0.1961\n",
            "Epoch 754/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1975\n",
            "Epoch 755/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1952\n",
            "Epoch 756/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1973\n",
            "Epoch 757/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1967\n",
            "Epoch 758/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1970\n",
            "Epoch 759/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1970\n",
            "Epoch 760/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1531 - val_loss: 0.1984\n",
            "Epoch 761/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1964\n",
            "Epoch 762/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1970\n",
            "Epoch 763/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1973\n",
            "Epoch 764/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1932\n",
            "Epoch 765/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1922\n",
            "Epoch 766/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1964\n",
            "Epoch 767/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1977\n",
            "Epoch 768/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1959\n",
            "Epoch 769/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1983\n",
            "Epoch 770/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1990\n",
            "Epoch 771/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1968\n",
            "Epoch 772/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1961\n",
            "Epoch 773/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1948\n",
            "Epoch 774/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1966\n",
            "Epoch 775/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1979\n",
            "Epoch 776/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1981\n",
            "Epoch 777/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1969\n",
            "Epoch 778/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1987\n",
            "Epoch 779/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1962\n",
            "Epoch 780/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1973\n",
            "Epoch 781/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1991\n",
            "Epoch 782/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1981\n",
            "Epoch 783/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1953\n",
            "Epoch 784/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1966\n",
            "Epoch 785/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1942\n",
            "Epoch 786/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1959\n",
            "Epoch 787/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1954\n",
            "Epoch 788/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1972\n",
            "Epoch 789/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1948\n",
            "Epoch 790/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1954\n",
            "Epoch 791/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1953\n",
            "Epoch 792/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1979\n",
            "Epoch 793/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1953\n",
            "Epoch 794/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1964\n",
            "Epoch 795/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1983\n",
            "Epoch 796/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1958\n",
            "Epoch 797/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1933\n",
            "Epoch 798/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1959\n",
            "Epoch 799/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1968\n",
            "Epoch 800/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1978\n",
            "Epoch 801/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1932\n",
            "Epoch 802/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1959\n",
            "Epoch 803/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1976\n",
            "Epoch 804/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1956\n",
            "Epoch 805/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1974\n",
            "Epoch 806/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1962\n",
            "Epoch 807/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1957\n",
            "Epoch 808/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1971\n",
            "Epoch 809/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1530 - val_loss: 0.1951\n",
            "Epoch 810/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1979\n",
            "Epoch 811/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1939\n",
            "Epoch 812/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1952\n",
            "Epoch 813/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1935\n",
            "Epoch 814/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1929\n",
            "Epoch 815/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1963\n",
            "Epoch 816/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1967\n",
            "Epoch 817/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1953\n",
            "Epoch 818/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1974\n",
            "Epoch 819/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1984\n",
            "Epoch 820/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1965\n",
            "Epoch 821/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1976\n",
            "Epoch 822/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1973\n",
            "Epoch 823/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1991\n",
            "Epoch 824/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1965\n",
            "Epoch 825/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1962\n",
            "Epoch 826/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1994\n",
            "Epoch 827/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1964\n",
            "Epoch 828/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1962\n",
            "Epoch 829/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1953\n",
            "Epoch 830/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1961\n",
            "Epoch 831/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1950\n",
            "Epoch 832/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1970\n",
            "Epoch 833/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1984\n",
            "Epoch 834/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1991\n",
            "Epoch 835/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1998\n",
            "Epoch 836/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1982\n",
            "Epoch 837/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1980\n",
            "Epoch 838/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1985\n",
            "Epoch 839/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1982\n",
            "Epoch 840/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1977\n",
            "Epoch 841/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1997\n",
            "Epoch 842/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1980\n",
            "Epoch 843/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1983\n",
            "Epoch 844/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1959\n",
            "Epoch 845/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1975\n",
            "Epoch 846/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1530 - val_loss: 0.1961\n",
            "Epoch 847/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1970\n",
            "Epoch 848/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1970\n",
            "Epoch 849/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1964\n",
            "Epoch 850/1000\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1530 - val_loss: 0.1979\n",
            "Epoch 851/1000\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1530 - val_loss: 0.1997\n",
            "Epoch 852/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1530 - val_loss: 0.1982\n",
            "Epoch 853/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1978\n",
            "Epoch 854/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1968\n",
            "Epoch 855/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1939\n",
            "Epoch 856/1000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1529 - val_loss: 0.1957\n",
            "Epoch 857/1000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1530 - val_loss: 0.1994\n",
            "Epoch 858/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1973\n",
            "Epoch 859/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1970\n",
            "Epoch 860/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1964\n",
            "Epoch 861/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1969\n",
            "Epoch 862/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1957\n",
            "Epoch 863/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1949\n",
            "Epoch 864/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1962\n",
            "Epoch 865/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1991\n",
            "Epoch 866/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1949\n",
            "Epoch 867/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1938\n",
            "Epoch 868/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1951\n",
            "Epoch 869/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1987\n",
            "Epoch 870/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1530 - val_loss: 0.1954\n",
            "Epoch 871/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1991\n",
            "Epoch 872/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1959\n",
            "Epoch 873/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1970\n",
            "Epoch 874/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1967\n",
            "Epoch 875/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1978\n",
            "Epoch 876/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1958\n",
            "Epoch 877/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1973\n",
            "Epoch 878/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1968\n",
            "Epoch 879/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1975\n",
            "Epoch 880/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1954\n",
            "Epoch 881/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1929\n",
            "Epoch 882/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1940\n",
            "Epoch 883/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1964\n",
            "Epoch 884/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1946\n",
            "Epoch 885/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1947\n",
            "Epoch 886/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1956\n",
            "Epoch 887/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1971\n",
            "Epoch 888/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1981\n",
            "Epoch 889/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1953\n",
            "Epoch 890/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1957\n",
            "Epoch 891/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1946\n",
            "Epoch 892/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1975\n",
            "Epoch 893/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1530 - val_loss: 0.1946\n",
            "Epoch 894/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1947\n",
            "Epoch 895/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1963\n",
            "Epoch 896/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1971\n",
            "Epoch 897/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1996\n",
            "Epoch 898/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1989\n",
            "Epoch 899/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1950\n",
            "Epoch 900/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1944\n",
            "Epoch 901/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1957\n",
            "Epoch 902/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1530 - val_loss: 0.1979\n",
            "Epoch 903/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.2016\n",
            "Epoch 904/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1530 - val_loss: 0.1944\n",
            "Epoch 905/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1947\n",
            "Epoch 906/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1964\n",
            "Epoch 907/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1935\n",
            "Epoch 908/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1950\n",
            "Epoch 909/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1949\n",
            "Epoch 910/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1966\n",
            "Epoch 911/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1968\n",
            "Epoch 912/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1939\n",
            "Epoch 913/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1955\n",
            "Epoch 914/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1530 - val_loss: 0.1959\n",
            "Epoch 915/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1530 - val_loss: 0.1961\n",
            "Epoch 916/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1952\n",
            "Epoch 917/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1956\n",
            "Epoch 918/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1957\n",
            "Epoch 919/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1956\n",
            "Epoch 920/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1992\n",
            "Epoch 921/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1969\n",
            "Epoch 922/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1973\n",
            "Epoch 923/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1963\n",
            "Epoch 924/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1960\n",
            "Epoch 925/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1956\n",
            "Epoch 926/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1930\n",
            "Epoch 927/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1945\n",
            "Epoch 928/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1941\n",
            "Epoch 929/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1974\n",
            "Epoch 930/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1970\n",
            "Epoch 931/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1984\n",
            "Epoch 932/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1958\n",
            "Epoch 933/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1957\n",
            "Epoch 934/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1990\n",
            "Epoch 935/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1965\n",
            "Epoch 936/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1972\n",
            "Epoch 937/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1958\n",
            "Epoch 938/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1980\n",
            "Epoch 939/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1989\n",
            "Epoch 940/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1968\n",
            "Epoch 941/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1963\n",
            "Epoch 942/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1970\n",
            "Epoch 943/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1984\n",
            "Epoch 944/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1961\n",
            "Epoch 945/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1969\n",
            "Epoch 946/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1950\n",
            "Epoch 947/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1973\n",
            "Epoch 948/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1954\n",
            "Epoch 949/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1941\n",
            "Epoch 950/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1976\n",
            "Epoch 951/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1935\n",
            "Epoch 952/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1984\n",
            "Epoch 953/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1956\n",
            "Epoch 954/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1915\n",
            "Epoch 955/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1944\n",
            "Epoch 956/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1950\n",
            "Epoch 957/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1960\n",
            "Epoch 958/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1968\n",
            "Epoch 959/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1974\n",
            "Epoch 960/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1949\n",
            "Epoch 961/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1938\n",
            "Epoch 962/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1967\n",
            "Epoch 963/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1974\n",
            "Epoch 964/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1956\n",
            "Epoch 965/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1941\n",
            "Epoch 966/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1941\n",
            "Epoch 967/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1989\n",
            "Epoch 968/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1974\n",
            "Epoch 969/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1949\n",
            "Epoch 970/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1962\n",
            "Epoch 971/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1978\n",
            "Epoch 972/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1949\n",
            "Epoch 973/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1979\n",
            "Epoch 974/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1964\n",
            "Epoch 975/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1976\n",
            "Epoch 976/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1957\n",
            "Epoch 977/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1955\n",
            "Epoch 978/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1950\n",
            "Epoch 979/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1966\n",
            "Epoch 980/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1967\n",
            "Epoch 981/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1962\n",
            "Epoch 982/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1969\n",
            "Epoch 983/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1990\n",
            "Epoch 984/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1986\n",
            "Epoch 985/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1974\n",
            "Epoch 986/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1967\n",
            "Epoch 987/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1996\n",
            "Epoch 988/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1984\n",
            "Epoch 989/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.1957\n",
            "Epoch 990/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1974\n",
            "Epoch 991/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1986\n",
            "Epoch 992/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1952\n",
            "Epoch 993/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1966\n",
            "Epoch 994/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1953\n",
            "Epoch 995/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1941\n",
            "Epoch 996/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1951\n",
            "Epoch 997/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1959\n",
            "Epoch 998/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1950\n",
            "Epoch 999/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1960\n",
            "Epoch 1000/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Loss = h.history['loss']\n",
        "Loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6pyiuvF9C8u",
        "outputId": "35cb330e-607e-4c2d-b47d-50efb66b5b04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3370108604431152,\n",
              " 1.2647217512130737,\n",
              " 1.1980067491531372,\n",
              " 1.1366325616836548,\n",
              " 1.0801353454589844,\n",
              " 1.0285942554473877,\n",
              " 0.9805356860160828,\n",
              " 0.9357685446739197,\n",
              " 0.8938179612159729,\n",
              " 0.854226291179657,\n",
              " 0.8163980841636658,\n",
              " 0.7803532481193542,\n",
              " 0.746191143989563,\n",
              " 0.7138199210166931,\n",
              " 0.6834538578987122,\n",
              " 0.6547979712486267,\n",
              " 0.6285397410392761,\n",
              " 0.6041882038116455,\n",
              " 0.5821382403373718,\n",
              " 0.5621266961097717,\n",
              " 0.5434098839759827,\n",
              " 0.5267061591148376,\n",
              " 0.5113332867622375,\n",
              " 0.4975837767124176,\n",
              " 0.4847470223903656,\n",
              " 0.4730782210826874,\n",
              " 0.4623537063598633,\n",
              " 0.45235463976860046,\n",
              " 0.4430852234363556,\n",
              " 0.4344392418861389,\n",
              " 0.4264337420463562,\n",
              " 0.41889268159866333,\n",
              " 0.41184988617897034,\n",
              " 0.40526899695396423,\n",
              " 0.3991053104400635,\n",
              " 0.3932340741157532,\n",
              " 0.38770580291748047,\n",
              " 0.3824078440666199,\n",
              " 0.37743812799453735,\n",
              " 0.37274834513664246,\n",
              " 0.3682217001914978,\n",
              " 0.36390596628189087,\n",
              " 0.3597489595413208,\n",
              " 0.35580557584762573,\n",
              " 0.3519827425479889,\n",
              " 0.34834492206573486,\n",
              " 0.3447987139225006,\n",
              " 0.34139642119407654,\n",
              " 0.338082879781723,\n",
              " 0.33495014905929565,\n",
              " 0.33184027671813965,\n",
              " 0.3288625180721283,\n",
              " 0.32594576478004456,\n",
              " 0.32312875986099243,\n",
              " 0.3203885853290558,\n",
              " 0.31773462891578674,\n",
              " 0.31511592864990234,\n",
              " 0.3125660717487335,\n",
              " 0.3100655674934387,\n",
              " 0.30765897035598755,\n",
              " 0.30527976155281067,\n",
              " 0.30296826362609863,\n",
              " 0.3007291853427887,\n",
              " 0.2985347807407379,\n",
              " 0.29634207487106323,\n",
              " 0.29424023628234863,\n",
              " 0.2921459972858429,\n",
              " 0.29014408588409424,\n",
              " 0.2881353199481964,\n",
              " 0.28619810938835144,\n",
              " 0.2842484712600708,\n",
              " 0.28240349888801575,\n",
              " 0.280536413192749,\n",
              " 0.27872705459594727,\n",
              " 0.2769322097301483,\n",
              " 0.27521926164627075,\n",
              " 0.27346405386924744,\n",
              " 0.2717762589454651,\n",
              " 0.2701214849948883,\n",
              " 0.26848819851875305,\n",
              " 0.2669048011302948,\n",
              " 0.2652871310710907,\n",
              " 0.26372992992401123,\n",
              " 0.26220643520355225,\n",
              " 0.2607417106628418,\n",
              " 0.25922492146492004,\n",
              " 0.2577795386314392,\n",
              " 0.2563588619232178,\n",
              " 0.25494346022605896,\n",
              " 0.2535882890224457,\n",
              " 0.2521762549877167,\n",
              " 0.25085681676864624,\n",
              " 0.24952153861522675,\n",
              " 0.24821197986602783,\n",
              " 0.24690355360507965,\n",
              " 0.24565213918685913,\n",
              " 0.2443852424621582,\n",
              " 0.24317514896392822,\n",
              " 0.2419966608285904,\n",
              " 0.2407834827899933,\n",
              " 0.23960942029953003,\n",
              " 0.23849594593048096,\n",
              " 0.2373107373714447,\n",
              " 0.23618443310260773,\n",
              " 0.2351224273443222,\n",
              " 0.23401160538196564,\n",
              " 0.23295067250728607,\n",
              " 0.2318580150604248,\n",
              " 0.23080110549926758,\n",
              " 0.22978152334690094,\n",
              " 0.22879499197006226,\n",
              " 0.22777925431728363,\n",
              " 0.22676198184490204,\n",
              " 0.22578854858875275,\n",
              " 0.2248470038175583,\n",
              " 0.2239190638065338,\n",
              " 0.22295626997947693,\n",
              " 0.22202911972999573,\n",
              " 0.22111913561820984,\n",
              " 0.22022582590579987,\n",
              " 0.21932752430438995,\n",
              " 0.21848386526107788,\n",
              " 0.2175997942686081,\n",
              " 0.21675808727741241,\n",
              " 0.21592316031455994,\n",
              " 0.21509279310703278,\n",
              " 0.21431782841682434,\n",
              " 0.213483527302742,\n",
              " 0.2127247154712677,\n",
              " 0.21193933486938477,\n",
              " 0.21119527518749237,\n",
              " 0.2104071080684662,\n",
              " 0.20964668691158295,\n",
              " 0.20890186727046967,\n",
              " 0.20819224417209625,\n",
              " 0.20743471384048462,\n",
              " 0.20676660537719727,\n",
              " 0.2060142159461975,\n",
              " 0.20535722374916077,\n",
              " 0.2046533226966858,\n",
              " 0.20398707687854767,\n",
              " 0.20333752036094666,\n",
              " 0.20266765356063843,\n",
              " 0.20199336111545563,\n",
              " 0.20134644210338593,\n",
              " 0.2007623016834259,\n",
              " 0.20011290907859802,\n",
              " 0.1994871199131012,\n",
              " 0.19888629019260406,\n",
              " 0.19830213487148285,\n",
              " 0.19771762192249298,\n",
              " 0.19709564745426178,\n",
              " 0.1965060532093048,\n",
              " 0.19594116508960724,\n",
              " 0.19538015127182007,\n",
              " 0.19484862685203552,\n",
              " 0.194327712059021,\n",
              " 0.1937556266784668,\n",
              " 0.19329498708248138,\n",
              " 0.1926846206188202,\n",
              " 0.1921822428703308,\n",
              " 0.19166651368141174,\n",
              " 0.19119273126125336,\n",
              " 0.1906736046075821,\n",
              " 0.1901666671037674,\n",
              " 0.18967406451702118,\n",
              " 0.18927954137325287,\n",
              " 0.18878109753131866,\n",
              " 0.18827399611473083,\n",
              " 0.18779928982257843,\n",
              " 0.18736149370670319,\n",
              " 0.1869136542081833,\n",
              " 0.18650278449058533,\n",
              " 0.1860831081867218,\n",
              " 0.18559670448303223,\n",
              " 0.18520282208919525,\n",
              " 0.18482665717601776,\n",
              " 0.18438264727592468,\n",
              " 0.18395507335662842,\n",
              " 0.18356499075889587,\n",
              " 0.1832754760980606,\n",
              " 0.1827888935804367,\n",
              " 0.18241848051548004,\n",
              " 0.182041198015213,\n",
              " 0.1816520243883133,\n",
              " 0.1813107579946518,\n",
              " 0.18092678487300873,\n",
              " 0.18056927621364594,\n",
              " 0.18020017445087433,\n",
              " 0.17984923720359802,\n",
              " 0.17956076562404633,\n",
              " 0.17922194302082062,\n",
              " 0.17892079055309296,\n",
              " 0.1785016804933548,\n",
              " 0.1782122552394867,\n",
              " 0.17789481580257416,\n",
              " 0.17757120728492737,\n",
              " 0.17732441425323486,\n",
              " 0.176933154463768,\n",
              " 0.17666247487068176,\n",
              " 0.17632514238357544,\n",
              " 0.17606867849826813,\n",
              " 0.1757594347000122,\n",
              " 0.1754489243030548,\n",
              " 0.1752440184354782,\n",
              " 0.17487846314907074,\n",
              " 0.17464062571525574,\n",
              " 0.1743834763765335,\n",
              " 0.17409181594848633,\n",
              " 0.17378972470760345,\n",
              " 0.17355428636074066,\n",
              " 0.1732661873102188,\n",
              " 0.17306289076805115,\n",
              " 0.17277628183364868,\n",
              " 0.1725534349679947,\n",
              " 0.1723221391439438,\n",
              " 0.17205801606178284,\n",
              " 0.17184390127658844,\n",
              " 0.17164622247219086,\n",
              " 0.17135560512542725,\n",
              " 0.1711474061012268,\n",
              " 0.17091025412082672,\n",
              " 0.17069600522518158,\n",
              " 0.17044545710086823,\n",
              " 0.17023958265781403,\n",
              " 0.17002534866333008,\n",
              " 0.16986912488937378,\n",
              " 0.16959863901138306,\n",
              " 0.16942310333251953,\n",
              " 0.16922453045845032,\n",
              " 0.16901102662086487,\n",
              " 0.16880758106708527,\n",
              " 0.1686689704656601,\n",
              " 0.16845455765724182,\n",
              " 0.1682872772216797,\n",
              " 0.16808587312698364,\n",
              " 0.16787247359752655,\n",
              " 0.16768963634967804,\n",
              " 0.16753847897052765,\n",
              " 0.16735661029815674,\n",
              " 0.16728080809116364,\n",
              " 0.16700610518455505,\n",
              " 0.16682519018650055,\n",
              " 0.1667202264070511,\n",
              " 0.16651387512683868,\n",
              " 0.16637364029884338,\n",
              " 0.16627727448940277,\n",
              " 0.16603420674800873,\n",
              " 0.16594146192073822,\n",
              " 0.165756493806839,\n",
              " 0.16559608280658722,\n",
              " 0.16546213626861572,\n",
              " 0.16529524326324463,\n",
              " 0.16516076028347015,\n",
              " 0.16501665115356445,\n",
              " 0.16486287117004395,\n",
              " 0.16472800076007843,\n",
              " 0.16463083028793335,\n",
              " 0.1644706279039383,\n",
              " 0.16434355080127716,\n",
              " 0.16423751413822174,\n",
              " 0.16404582560062408,\n",
              " 0.1639586240053177,\n",
              " 0.16379231214523315,\n",
              " 0.16375631093978882,\n",
              " 0.16366496682167053,\n",
              " 0.16343015432357788,\n",
              " 0.16331851482391357,\n",
              " 0.16322574019432068,\n",
              " 0.16307038068771362,\n",
              " 0.16298359632492065,\n",
              " 0.16284993290901184,\n",
              " 0.16273708641529083,\n",
              " 0.16265778243541718,\n",
              " 0.16255028545856476,\n",
              " 0.1624215990304947,\n",
              " 0.16230422258377075,\n",
              " 0.162266343832016,\n",
              " 0.16209106147289276,\n",
              " 0.16200757026672363,\n",
              " 0.16189509630203247,\n",
              " 0.1617830991744995,\n",
              " 0.16178105771541595,\n",
              " 0.16157904267311096,\n",
              " 0.16151317954063416,\n",
              " 0.1614639312028885,\n",
              " 0.1613205522298813,\n",
              " 0.16120107471942902,\n",
              " 0.16123811900615692,\n",
              " 0.16105003654956818,\n",
              " 0.16094043850898743,\n",
              " 0.16087622940540314,\n",
              " 0.16076968610286713,\n",
              " 0.16069042682647705,\n",
              " 0.16060298681259155,\n",
              " 0.1605250984430313,\n",
              " 0.16044074296951294,\n",
              " 0.16037026047706604,\n",
              " 0.1603059023618698,\n",
              " 0.16018730401992798,\n",
              " 0.16014182567596436,\n",
              " 0.1601020246744156,\n",
              " 0.15997736155986786,\n",
              " 0.15995751321315765,\n",
              " 0.15985015034675598,\n",
              " 0.1597682684659958,\n",
              " 0.15979790687561035,\n",
              " 0.1596211940050125,\n",
              " 0.15957437455654144,\n",
              " 0.15951868891716003,\n",
              " 0.15945596992969513,\n",
              " 0.15935875475406647,\n",
              " 0.1593656688928604,\n",
              " 0.15922828018665314,\n",
              " 0.15917927026748657,\n",
              " 0.15911220014095306,\n",
              " 0.15910765528678894,\n",
              " 0.1589600145816803,\n",
              " 0.15891316533088684,\n",
              " 0.15884707868099213,\n",
              " 0.15879550576210022,\n",
              " 0.1587604135274887,\n",
              " 0.15872013568878174,\n",
              " 0.15864713490009308,\n",
              " 0.15859335660934448,\n",
              " 0.15854878723621368,\n",
              " 0.15845245122909546,\n",
              " 0.15845908224582672,\n",
              " 0.15836551785469055,\n",
              " 0.15828080475330353,\n",
              " 0.15826857089996338,\n",
              " 0.1582101434469223,\n",
              " 0.1581590324640274,\n",
              " 0.15814504027366638,\n",
              " 0.15803349018096924,\n",
              " 0.15799733996391296,\n",
              " 0.15794306993484497,\n",
              " 0.15788671374320984,\n",
              " 0.15784300863742828,\n",
              " 0.15779301524162292,\n",
              " 0.15779255330562592,\n",
              " 0.1576939970254898,\n",
              " 0.1576438844203949,\n",
              " 0.15760619938373566,\n",
              " 0.15758319199085236,\n",
              " 0.15753217041492462,\n",
              " 0.1574813574552536,\n",
              " 0.1574501395225525,\n",
              " 0.1574261635541916,\n",
              " 0.15734542906284332,\n",
              " 0.15735776722431183,\n",
              " 0.1572580188512802,\n",
              " 0.15723025798797607,\n",
              " 0.15718308091163635,\n",
              " 0.15714840590953827,\n",
              " 0.15711472928524017,\n",
              " 0.157081738114357,\n",
              " 0.15701429545879364,\n",
              " 0.1570221185684204,\n",
              " 0.15697120130062103,\n",
              " 0.15692394971847534,\n",
              " 0.1568894386291504,\n",
              " 0.15684635937213898,\n",
              " 0.15679863095283508,\n",
              " 0.15677867829799652,\n",
              " 0.15678372979164124,\n",
              " 0.1567729264497757,\n",
              " 0.15665596723556519,\n",
              " 0.15664200484752655,\n",
              " 0.1565941423177719,\n",
              " 0.15660439431667328,\n",
              " 0.15657395124435425,\n",
              " 0.15655040740966797,\n",
              " 0.15644603967666626,\n",
              " 0.15649059414863586,\n",
              " 0.15639574825763702,\n",
              " 0.15641766786575317,\n",
              " 0.15635912120342255,\n",
              " 0.15630760788917542,\n",
              " 0.15626651048660278,\n",
              " 0.15624773502349854,\n",
              " 0.15622112154960632,\n",
              " 0.15626095235347748,\n",
              " 0.1561574935913086,\n",
              " 0.15612611174583435,\n",
              " 0.1560998409986496,\n",
              " 0.15606321394443512,\n",
              " 0.1560792326927185,\n",
              " 0.156027689576149,\n",
              " 0.15603119134902954,\n",
              " 0.15593475103378296,\n",
              " 0.1559198945760727,\n",
              " 0.15594591200351715,\n",
              " 0.15593262016773224,\n",
              " 0.15585926175117493,\n",
              " 0.1558317244052887,\n",
              " 0.15582796931266785,\n",
              " 0.15579307079315186,\n",
              " 0.15574334561824799,\n",
              " 0.15575024485588074,\n",
              " 0.15569281578063965,\n",
              " 0.1557331532239914,\n",
              " 0.15567626059055328,\n",
              " 0.15567848086357117,\n",
              " 0.15565651655197144,\n",
              " 0.15560674667358398,\n",
              " 0.15556740760803223,\n",
              " 0.15558920800685883,\n",
              " 0.15552249550819397,\n",
              " 0.155486062169075,\n",
              " 0.15546377003192902,\n",
              " 0.1554819643497467,\n",
              " 0.15547198057174683,\n",
              " 0.15539151430130005,\n",
              " 0.15538716316223145,\n",
              " 0.1553952693939209,\n",
              " 0.15539242327213287,\n",
              " 0.15537069737911224,\n",
              " 0.15534473955631256,\n",
              " 0.1553291380405426,\n",
              " 0.15526852011680603,\n",
              " 0.1552446335554123,\n",
              " 0.1552741527557373,\n",
              " 0.15519596636295319,\n",
              " 0.15520691871643066,\n",
              " 0.15523070096969604,\n",
              " 0.1551983654499054,\n",
              " 0.15514034032821655,\n",
              " 0.15517014265060425,\n",
              " 0.15507769584655762,\n",
              " 0.1551537662744522,\n",
              " 0.15507899224758148,\n",
              " 0.1550477296113968,\n",
              " 0.1550038456916809,\n",
              " 0.15501521527767181,\n",
              " 0.15502133965492249,\n",
              " 0.15499788522720337,\n",
              " 0.1549389809370041,\n",
              " 0.15494686365127563,\n",
              " 0.1549396812915802,\n",
              " 0.15491604804992676,\n",
              " 0.1548876017332077,\n",
              " 0.15487529337406158,\n",
              " 0.15485472977161407,\n",
              " 0.15485206246376038,\n",
              " 0.1548296958208084,\n",
              " 0.1548033505678177,\n",
              " 0.15479622781276703,\n",
              " 0.1547987163066864,\n",
              " 0.15477421879768372,\n",
              " 0.1547500491142273,\n",
              " 0.15477359294891357,\n",
              " 0.15472236275672913,\n",
              " 0.15471796691417694,\n",
              " 0.1546759009361267,\n",
              " 0.15472179651260376,\n",
              " 0.1546451896429062,\n",
              " 0.15470807254314423,\n",
              " 0.15471020340919495,\n",
              " 0.15464487671852112,\n",
              " 0.15461888909339905,\n",
              " 0.15461044013500214,\n",
              " 0.15459367632865906,\n",
              " 0.1545783132314682,\n",
              " 0.15452013909816742,\n",
              " 0.15452972054481506,\n",
              " 0.1545625478029251,\n",
              " 0.15450845658779144,\n",
              " 0.15448135137557983,\n",
              " 0.15451277792453766,\n",
              " 0.15448971092700958,\n",
              " 0.1544959992170334,\n",
              " 0.15444442629814148,\n",
              " 0.15445268154144287,\n",
              " 0.1544862985610962,\n",
              " 0.15442605316638947,\n",
              " 0.15443852543830872,\n",
              " 0.15441317856311798,\n",
              " 0.15439604222774506,\n",
              " 0.15438158810138702,\n",
              " 0.1543724238872528,\n",
              " 0.15434952080249786,\n",
              " 0.1543375700712204,\n",
              " 0.15431474149227142,\n",
              " 0.15434028208255768,\n",
              " 0.1543302834033966,\n",
              " 0.15430186688899994,\n",
              " 0.15435250103473663,\n",
              " 0.15426883101463318,\n",
              " 0.15431419014930725,\n",
              " 0.1542341709136963,\n",
              " 0.15423007309436798,\n",
              " 0.15422484278678894,\n",
              " 0.15425395965576172,\n",
              " 0.15420161187648773,\n",
              " 0.15419167280197144,\n",
              " 0.15421180427074432,\n",
              " 0.15420880913734436,\n",
              " 0.1541755050420761,\n",
              " 0.1541702002286911,\n",
              " 0.15418776869773865,\n",
              " 0.15413109958171844,\n",
              " 0.15414077043533325,\n",
              " 0.15414674580097198,\n",
              " 0.15410734713077545,\n",
              " 0.15412035584449768,\n",
              " 0.1540994644165039,\n",
              " 0.15416255593299866,\n",
              " 0.15408147871494293,\n",
              " 0.15406835079193115,\n",
              " 0.15405307710170746,\n",
              " 0.1540421098470688,\n",
              " 0.15406101942062378,\n",
              " 0.15405502915382385,\n",
              " 0.15401588380336761,\n",
              " 0.15403634309768677,\n",
              " 0.15407443046569824,\n",
              " 0.15401285886764526,\n",
              " 0.15403969585895538,\n",
              " 0.1539953052997589,\n",
              " 0.15396082401275635,\n",
              " 0.15399357676506042,\n",
              " 0.1539621204137802,\n",
              " 0.15395674109458923,\n",
              " 0.15393729507923126,\n",
              " 0.1539599597454071,\n",
              " 0.15390700101852417,\n",
              " 0.15392090380191803,\n",
              " 0.1539144068956375,\n",
              " 0.1539410948753357,\n",
              " 0.15391522645950317,\n",
              " 0.1538850963115692,\n",
              " 0.15392452478408813,\n",
              " 0.15386833250522614,\n",
              " 0.15390659868717194,\n",
              " 0.15385562181472778,\n",
              " 0.15385085344314575,\n",
              " 0.15384571254253387,\n",
              " 0.15388020873069763,\n",
              " 0.1538386344909668,\n",
              " 0.1538255363702774,\n",
              " 0.15382416546344757,\n",
              " 0.15380802750587463,\n",
              " 0.15380723774433136,\n",
              " 0.1538124680519104,\n",
              " 0.15382930636405945,\n",
              " 0.15377768874168396,\n",
              " 0.1539781540632248,\n",
              " 0.15377889573574066,\n",
              " 0.15375632047653198,\n",
              " 0.1537473350763321,\n",
              " 0.15377870202064514,\n",
              " 0.15375101566314697,\n",
              " 0.15373918414115906,\n",
              " 0.15375669300556183,\n",
              " 0.1537242829799652,\n",
              " 0.15370962023735046,\n",
              " 0.1537109911441803,\n",
              " 0.15371276438236237,\n",
              " 0.15371742844581604,\n",
              " 0.1536918431520462,\n",
              " 0.1536819338798523,\n",
              " 0.15368832647800446,\n",
              " 0.15369272232055664,\n",
              " 0.15370038151741028,\n",
              " 0.15367437899112701,\n",
              " 0.15371596813201904,\n",
              " 0.15369199216365814,\n",
              " 0.15364016592502594,\n",
              " 0.15366202592849731,\n",
              " 0.15365241467952728,\n",
              " 0.15368017554283142,\n",
              " 0.1536383181810379,\n",
              " 0.15360620617866516,\n",
              " 0.1536172479391098,\n",
              " 0.15361294150352478,\n",
              " 0.15360237658023834,\n",
              " 0.15362001955509186,\n",
              " 0.15361925959587097,\n",
              " 0.15360714495182037,\n",
              " 0.15357449650764465,\n",
              " 0.15359219908714294,\n",
              " 0.15358279645442963,\n",
              " 0.1535670906305313,\n",
              " 0.15359006822109222,\n",
              " 0.15359213948249817,\n",
              " 0.1535794883966446,\n",
              " 0.1535385698080063,\n",
              " 0.15356619656085968,\n",
              " 0.15354757010936737,\n",
              " 0.1535496711730957,\n",
              " 0.15354688465595245,\n",
              " 0.15352530777454376,\n",
              " 0.15352417528629303,\n",
              " 0.15352575480937958,\n",
              " 0.1535435914993286,\n",
              " 0.1535123586654663,\n",
              " 0.15352879464626312,\n",
              " 0.15351872146129608,\n",
              " 0.15350711345672607,\n",
              " 0.1534949094057083,\n",
              " 0.15355318784713745,\n",
              " 0.15348803997039795,\n",
              " 0.15347760915756226,\n",
              " 0.1534992903470993,\n",
              " 0.15347959101200104,\n",
              " 0.153501957654953,\n",
              " 0.1534721851348877,\n",
              " 0.15345993638038635,\n",
              " 0.15346704423427582,\n",
              " 0.15345093607902527,\n",
              " 0.15345454216003418,\n",
              " 0.15348897874355316,\n",
              " 0.15349820256233215,\n",
              " 0.15341134369373322,\n",
              " 0.1534939408302307,\n",
              " 0.1534452885389328,\n",
              " 0.15341660380363464,\n",
              " 0.15344911813735962,\n",
              " 0.153408020734787,\n",
              " 0.1534055918455124,\n",
              " 0.15339607000350952,\n",
              " 0.15342700481414795,\n",
              " 0.15338078141212463,\n",
              " 0.15345560014247894,\n",
              " 0.15337786078453064,\n",
              " 0.15339410305023193,\n",
              " 0.1533704698085785,\n",
              " 0.15339744091033936,\n",
              " 0.15337392687797546,\n",
              " 0.15337315201759338,\n",
              " 0.15335197746753693,\n",
              " 0.1533711701631546,\n",
              " 0.1533491313457489,\n",
              " 0.15335713326931,\n",
              " 0.15334129333496094,\n",
              " 0.15337330102920532,\n",
              " 0.15333271026611328,\n",
              " 0.15334078669548035,\n",
              " 0.15334369242191315,\n",
              " 0.15340656042099,\n",
              " 0.15334394574165344,\n",
              " 0.1533217579126358,\n",
              " 0.153319850564003,\n",
              " 0.15332955121994019,\n",
              " 0.15331506729125977,\n",
              " 0.15331660211086273,\n",
              " 0.15334904193878174,\n",
              " 0.15329165756702423,\n",
              " 0.15331582725048065,\n",
              " 0.1533711850643158,\n",
              " 0.15332598984241486,\n",
              " 0.15331757068634033,\n",
              " 0.15334735810756683,\n",
              " 0.15332727134227753,\n",
              " 0.15339034795761108,\n",
              " 0.15330670773983002,\n",
              " 0.1532922238111496,\n",
              " 0.15329614281654358,\n",
              " 0.15326599776744843,\n",
              " 0.1532793492078781,\n",
              " 0.1532788723707199,\n",
              " 0.1532621532678604,\n",
              " 0.15326985716819763,\n",
              " 0.15333326160907745,\n",
              " 0.15326806902885437,\n",
              " 0.15329335629940033,\n",
              " 0.1532653272151947,\n",
              " 0.15325312316417694,\n",
              " 0.15325072407722473,\n",
              " 0.15324261784553528,\n",
              " 0.15329185128211975,\n",
              " 0.15325148403644562,\n",
              " 0.1532910019159317,\n",
              " 0.15323302149772644,\n",
              " 0.15326960384845734,\n",
              " 0.15323099493980408,\n",
              " 0.15323695540428162,\n",
              " 0.15324699878692627,\n",
              " 0.1532278060913086,\n",
              " 0.15323756635189056,\n",
              " 0.1532350480556488,\n",
              " 0.15325239300727844,\n",
              " 0.15321806073188782,\n",
              " 0.153197780251503,\n",
              " 0.1532071828842163,\n",
              " 0.15326237678527832,\n",
              " 0.15322187542915344,\n",
              " 0.15320077538490295,\n",
              " 0.15325164794921875,\n",
              " 0.1532517373561859,\n",
              " 0.15322671830654144,\n",
              " 0.15321126580238342,\n",
              " 0.1531739979982376,\n",
              " 0.15320031344890594,\n",
              " 0.15317963063716888,\n",
              " 0.15317624807357788,\n",
              " 0.15326756238937378,\n",
              " 0.15320903062820435,\n",
              " 0.15318623185157776,\n",
              " 0.15318380296230316,\n",
              " 0.1531815528869629,\n",
              " 0.15318912267684937,\n",
              " 0.15319550037384033,\n",
              " 0.15321172773838043,\n",
              " 0.15319424867630005,\n",
              " 0.153152197599411,\n",
              " 0.15316540002822876,\n",
              " 0.15321193635463715,\n",
              " 0.15327075123786926,\n",
              " 0.15317507088184357,\n",
              " 0.15316811203956604,\n",
              " 0.15314981341362,\n",
              " 0.15319421887397766,\n",
              " 0.15313421189785004,\n",
              " 0.15316708385944366,\n",
              " 0.1531553715467453,\n",
              " 0.15316325426101685,\n",
              " 0.15314999222755432,\n",
              " 0.15320129692554474,\n",
              " 0.15312165021896362,\n",
              " 0.1531766951084137,\n",
              " 0.15316924452781677,\n",
              " 0.15317866206169128,\n",
              " 0.1531350016593933,\n",
              " 0.15314939618110657,\n",
              " 0.1531289666891098,\n",
              " 0.15315048396587372,\n",
              " 0.1531381756067276,\n",
              " 0.15310992300510406,\n",
              " 0.15315915644168854,\n",
              " 0.1531350016593933,\n",
              " 0.15312109887599945,\n",
              " 0.15314757823944092,\n",
              " 0.15315160155296326,\n",
              " 0.15309856832027435,\n",
              " 0.1531163603067398,\n",
              " 0.15312780439853668,\n",
              " 0.1531304121017456,\n",
              " 0.15312710404396057,\n",
              " 0.15310828387737274,\n",
              " 0.15312957763671875,\n",
              " 0.153106689453125,\n",
              " 0.15310551226139069,\n",
              " 0.15309454500675201,\n",
              " 0.15307962894439697,\n",
              " 0.15311048924922943,\n",
              " 0.1531260460615158,\n",
              " 0.15311045944690704,\n",
              " 0.15306757390499115,\n",
              " 0.1531016081571579,\n",
              " 0.15313617885112762,\n",
              " 0.1530909538269043,\n",
              " 0.1530730128288269,\n",
              " 0.15313096344470978,\n",
              " 0.1531163901090622,\n",
              " 0.1531025767326355,\n",
              " 0.15310531854629517,\n",
              " 0.15307550132274628,\n",
              " 0.1531093567609787,\n",
              " 0.15311852097511292,\n",
              " 0.15306983888149261,\n",
              " 0.15311859548091888,\n",
              " 0.15304020047187805,\n",
              " 0.15311822295188904,\n",
              " 0.1530454456806183,\n",
              " 0.1530764251947403,\n",
              " 0.1531066745519638,\n",
              " 0.15307578444480896,\n",
              " 0.15307170152664185,\n",
              " 0.15306802093982697,\n",
              " 0.15306062996387482,\n",
              " 0.1530875861644745,\n",
              " 0.15307535231113434,\n",
              " 0.15304812788963318,\n",
              " 0.15305015444755554,\n",
              " 0.15308642387390137,\n",
              " 0.1530763953924179,\n",
              " 0.15306726098060608,\n",
              " 0.153031125664711,\n",
              " 0.15305428206920624,\n",
              " 0.15305975079536438,\n",
              " 0.15304049849510193,\n",
              " 0.1530909240245819,\n",
              " 0.15305571258068085,\n",
              " 0.15304741263389587,\n",
              " 0.1530696153640747,\n",
              " 0.15309207141399384,\n",
              " 0.15302631258964539,\n",
              " 0.15305757522583008,\n",
              " 0.15305830538272858,\n",
              " 0.1531149297952652,\n",
              " 0.15306356549263,\n",
              " 0.1530381739139557,\n",
              " 0.15304170548915863,\n",
              " 0.15303124487400055,\n",
              " 0.15304264426231384,\n",
              " 0.15301422774791718,\n",
              " 0.15302501618862152,\n",
              " 0.15311841666698456,\n",
              " 0.15303470194339752,\n",
              " 0.1530183106660843,\n",
              " 0.15306775271892548,\n",
              " 0.15300080180168152,\n",
              " 0.15301591157913208,\n",
              " 0.15304604172706604,\n",
              " 0.1529902070760727,\n",
              " 0.15304535627365112,\n",
              " 0.1530045121908188,\n",
              " 0.15314379334449768,\n",
              " 0.15302897989749908,\n",
              " 0.15301844477653503,\n",
              " 0.15300118923187256,\n",
              " 0.15302659571170807,\n",
              " 0.1530238837003708,\n",
              " 0.15303443372249603,\n",
              " 0.15303151309490204,\n",
              " 0.1530071496963501,\n",
              " 0.1530359387397766,\n",
              " 0.1530141681432724,\n",
              " 0.15300726890563965,\n",
              " 0.15301275253295898,\n",
              " 0.1530255824327469,\n",
              " 0.15300646424293518,\n",
              " 0.15301921963691711,\n",
              " 0.15298046171665192,\n",
              " 0.15300750732421875,\n",
              " 0.15309303998947144,\n",
              " 0.1529882401227951,\n",
              " 0.15300825238227844,\n",
              " 0.1529865860939026,\n",
              " 0.15305951237678528,\n",
              " 0.1530335247516632,\n",
              " 0.1530161201953888,\n",
              " 0.15305505692958832,\n",
              " 0.15300175547599792,\n",
              " 0.15301713347434998,\n",
              " 0.15301385521888733,\n",
              " 0.15299305319786072,\n",
              " 0.15299706161022186,\n",
              " 0.1529807150363922,\n",
              " 0.1529769003391266,\n",
              " 0.1530030220746994,\n",
              " 0.1529948115348816,\n",
              " 0.15297362208366394,\n",
              " 0.15296854078769684,\n",
              " 0.15296068787574768,\n",
              " 0.1529705673456192,\n",
              " 0.1529747098684311,\n",
              " 0.15299272537231445,\n",
              " 0.1529858559370041,\n",
              " 0.1529734879732132,\n",
              " 0.15297773480415344,\n",
              " 0.15297816693782806,\n",
              " 0.15301235020160675,\n",
              " 0.15294769406318665,\n",
              " 0.15298619866371155,\n",
              " 0.15299849212169647,\n",
              " 0.15299852192401886,\n",
              " 0.15295951068401337,\n",
              " 0.15297676622867584,\n",
              " 0.15294964611530304,\n",
              " 0.1529914289712906,\n",
              " 0.15295428037643433,\n",
              " 0.1530904918909073,\n",
              " 0.15302760899066925,\n",
              " 0.152993306517601,\n",
              " 0.152967169880867,\n",
              " 0.15296177566051483,\n",
              " 0.1530037671327591,\n",
              " 0.15297922492027283,\n",
              " 0.15294581651687622,\n",
              " 0.1529691070318222,\n",
              " 0.15293987095355988,\n",
              " 0.15300050377845764,\n",
              " 0.1529414802789688,\n",
              " 0.1529628336429596,\n",
              " 0.15296955406665802,\n",
              " 0.1530115306377411,\n",
              " 0.15291908383369446,\n",
              " 0.15292485058307648,\n",
              " 0.1530032455921173,\n",
              " 0.15300214290618896,\n",
              " 0.15296709537506104,\n",
              " 0.15295402705669403,\n",
              " 0.15293897688388824,\n",
              " 0.1529264748096466,\n",
              " 0.15301291644573212,\n",
              " 0.15296854078769684,\n",
              " 0.15294556319713593,\n",
              " 0.15295159816741943,\n",
              " 0.1529768705368042,\n",
              " 0.15297631919384003,\n",
              " 0.15294213593006134,\n",
              " 0.1529218703508377,\n",
              " 0.15298259258270264,\n",
              " 0.15295347571372986,\n",
              " 0.15294860303401947,\n",
              " 0.15293462574481964,\n",
              " 0.15299302339553833,\n",
              " 0.1529289186000824,\n",
              " 0.1529587209224701,\n",
              " 0.15301468968391418,\n",
              " 0.15302228927612305,\n",
              " 0.15295356512069702,\n",
              " 0.15298308432102203,\n",
              " 0.15291234850883484,\n",
              " 0.15294517576694489,\n",
              " 0.15294170379638672,\n",
              " 0.15291859209537506,\n",
              " 0.1529293805360794,\n",
              " 0.15295177698135376,\n",
              " 0.1529441773891449,\n",
              " 0.1530151218175888,\n",
              " 0.15296334028244019,\n",
              " 0.1529405266046524,\n",
              " 0.15293630957603455,\n",
              " 0.15291818976402283,\n",
              " 0.1529390662908554,\n",
              " 0.15293945372104645,\n",
              " 0.15292814373970032,\n",
              " 0.1529397815465927,\n",
              " 0.15288963913917542,\n",
              " 0.1529226452112198,\n",
              " 0.15291817486286163,\n",
              " 0.1530080884695053,\n",
              " 0.1529494822025299,\n",
              " 0.1529226452112198,\n",
              " 0.15294434130191803,\n",
              " 0.15292856097221375,\n",
              " 0.1529511958360672,\n",
              " 0.15293067693710327,\n",
              " 0.1529015302658081,\n",
              " 0.15294797718524933,\n",
              " 0.15293431282043457,\n",
              " 0.1529281735420227,\n",
              " 0.15296043455600739,\n",
              " 0.1529446840286255,\n",
              " 0.15291722118854523,\n",
              " 0.15289612114429474,\n",
              " 0.15294040739536285,\n",
              " 0.15291187167167664,\n",
              " 0.15295448899269104,\n",
              " 0.152923122048378,\n",
              " 0.1529218703508377,\n",
              " 0.15292410552501678,\n",
              " 0.152901753783226,\n",
              " 0.15295249223709106,\n",
              " 0.1529119312763214,\n",
              " 0.15294460952281952,\n",
              " 0.15298575162887573,\n",
              " 0.15290316939353943,\n",
              " 0.15289372205734253,\n",
              " 0.1529180109500885,\n",
              " 0.15291617810726166,\n",
              " 0.1529519408941269,\n",
              " 0.15290433168411255,\n",
              " 0.15292701125144958,\n",
              " 0.1529199182987213,\n",
              " 0.15291854739189148,\n",
              " 0.15291424095630646,\n",
              " 0.1529209464788437,\n",
              " 0.15291287004947662,\n",
              " 0.1529240608215332,\n",
              " 0.15292240679264069,\n",
              " 0.1529085785150528,\n",
              " 0.15301743149757385,\n",
              " 0.15291182696819305,\n",
              " 0.15288247168064117,\n",
              " 0.15288357436656952,\n",
              " 0.15290099382400513,\n",
              " 0.15291644632816315,\n",
              " 0.15294672548770905,\n",
              " 0.15289084613323212,\n",
              " 0.15292371809482574,\n",
              " 0.15288567543029785,\n",
              " 0.15290939807891846,\n",
              " 0.15288037061691284,\n",
              " 0.15292233228683472,\n",
              " 0.15287461876869202,\n",
              " 0.15291030704975128,\n",
              " 0.1528879553079605,\n",
              " 0.1528937667608261,\n",
              " 0.15289969742298126,\n",
              " 0.1529001146554947,\n",
              " 0.1529145985841751,\n",
              " 0.15286779403686523,\n",
              " 0.1528824418783188,\n",
              " 0.15296931564807892,\n",
              " 0.15288585424423218,\n",
              " 0.15290039777755737,\n",
              " 0.1529109627008438,\n",
              " 0.15287992358207703,\n",
              " 0.15286143124103546,\n",
              " 0.15291322767734528,\n",
              " 0.15287907421588898,\n",
              " 0.15293265879154205,\n",
              " 0.15290330350399017,\n",
              " 0.15286415815353394,\n",
              " 0.1528845578432083]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_weights()\n",
        "\n",
        "print(weights[0])\n",
        "print(weights[1])    #bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmjhQETI9FQI",
        "outputId": "95a647f1-bdec-4324-f039-790f6bd5c350"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.963214   0.392408   1.4140855]\n",
            " [-0.9900861  1.5471411 -1.2999952]]\n",
            "[ 8.10579   -5.5480375 -7.5953736]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(np.arange(epochs),h.history['loss'])\n",
        "plt.scatter(np.arange(epochs),h.history['val_loss'],c='r')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "VEvgrqmy9HhU",
        "outputId": "40f66932-e80c-495c-ed67-dfdf108ad816"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([[4,6]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLpbz1svHiRv",
        "outputId": "ed246c1b-b53d-472d-c23f-ae144fe17440"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 86ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6835167e-05, 9.9998295e-01, 2.9289262e-07]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}